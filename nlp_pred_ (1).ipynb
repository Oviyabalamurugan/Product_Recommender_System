{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "nlp_pred_.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BkIq4HCInM93"
      },
      "source": [
        "CB.EN.U4CSE19301 - Adheena B"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f4vJrSsKfp7J"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import spacy\n",
        "import string\n",
        "import pickle\n",
        "from spacy.lang.en.stop_words import STOP_WORDS\n",
        "from spacy.lang.en import English\n",
        "from sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "from sklearn.base import TransformerMixin \n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "80nxp1JQdKxw",
        "outputId": "6c37f792-c2e9-4348-f632-82ac82bb19df"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "As27pQJchaD6",
        "outputId": "0d8b8f4c-ad1c-4894-d602-89994d67a4b5"
      },
      "source": [
        "revs = pd.read_csv('/content/drive/MyDrive/Machine Learning/review3.csv', error_bad_lines=False)\n",
        "revs.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(306684, 5)"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "VYQ9Iz6uhhnf",
        "outputId": "c6542083-7665-4047-bdb1-33ece6237710"
      },
      "source": [
        "revs.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>reviewerID</th>\n",
              "      <th>asin</th>\n",
              "      <th>reviews</th>\n",
              "      <th>rating</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>A2QK1U70OJ74P</td>\n",
              "      <td>B000FA64PA</td>\n",
              "      <td>well written  interesting to see sideous  thro...</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>A3SZMGJMV0G16C</td>\n",
              "      <td>B000FA64PK</td>\n",
              "      <td>troy denning s novella recovery was originally...</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>A38Z3Q6DTDIH9J</td>\n",
              "      <td>B000FA64PK</td>\n",
              "      <td>another well written ebook by troy denning  bu...</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>A3SZMGJMV0G16C</td>\n",
              "      <td>B000FA64QO</td>\n",
              "      <td>with ylesia  a novella originally published in...</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>A22CW0ZHY3NJH8</td>\n",
              "      <td>B000FA64QO</td>\n",
              "      <td>the events of  ylesia  take place during  dest...</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       reviewerID        asin  ... rating  sentiment\n",
              "0   A2QK1U70OJ74P  B000FA64PA  ...      3          0\n",
              "1  A3SZMGJMV0G16C  B000FA64PK  ...      3          0\n",
              "2  A38Z3Q6DTDIH9J  B000FA64PK  ...      3          0\n",
              "3  A3SZMGJMV0G16C  B000FA64QO  ...      2          0\n",
              "4  A22CW0ZHY3NJH8  B000FA64QO  ...      3          0\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MRmuf9Zjp_N1",
        "outputId": "806f0cf5-a9a4-4196-9b13-b31ac1ca770d"
      },
      "source": [
        "revs.isna().sum()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "reviewerID    0\n",
              "asin          0\n",
              "reviews       0\n",
              "rating        0\n",
              "sentiment     0\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "smtqmPAfQWt6",
        "outputId": "c26a7813-cc72-40f9-92a1-069ac17f4f51"
      },
      "source": [
        "revs.asin.value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "B006GWO5WK    335\n",
              "B0093MU7QS    230\n",
              "B00BTIDW4S    221\n",
              "B005C5YZ86    182\n",
              "B007YJ3JV2    145\n",
              "             ... \n",
              "B005VRZXOA      1\n",
              "B005U7F1YS      1\n",
              "B00CNCUL2U      1\n",
              "B00I1R8WVI      1\n",
              "B004TU4YD6      1\n",
              "Name: asin, Length: 57450, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-MPzLH7MQdlY",
        "outputId": "1f6eadfb-2d94-4c5d-c41d-b180ebd1cf78"
      },
      "source": [
        "revs.reviewerID.value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "A3A7FF87LEVCQ1    571\n",
              "A13QTZ8CIMHHG4    403\n",
              "A2VXSQHJWZAQGY    389\n",
              "A20R37WRPLUM1D    286\n",
              "A8MTDB180W1XE     256\n",
              "                 ... \n",
              "ADP7WXXL52ZQM       1\n",
              "A2OYWI3HZJGIL2      1\n",
              "A1APCB56AV2LQ7      1\n",
              "AQ3DINQH0WH46       1\n",
              "AFMG0Z68FCJ6A       1\n",
              "Name: reviewerID, Length: 61920, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jw6vtSEon__1"
      },
      "source": [
        "# Load English tokenizer, tagger, parser, NER and word vectors\n",
        "nlp = English()\n",
        "stopwords = list(STOP_WORDS)\n",
        "punctuations = string.punctuation"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bklFxeyVnTPa"
      },
      "source": [
        "We’ll create a tokenizer() function that accepts a sentence as input and processes the sentence into tokens, performing lemmatization, lowercasing, and removing stop words"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B0oj2q75oE4Q"
      },
      "source": [
        "def tokenizer(sentence):\n",
        "    # create documents with linguistic annotations\n",
        "    mytokens = nlp(sentence)\n",
        "    mytokens = [ word.lemma_.lower().strip() if word.lemma_ != \"-PRON-\" else word.lower_ for word in mytokens ]\n",
        "    mytokens = [ word for word in mytokens if word not in stopwords and word not in punctuations ]\n",
        "    return mytokens"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ndkqdgwknhq7"
      },
      "source": [
        "To further clean our text data, we’ll also want to create a custom transformer for removing initial and end spaces and converting text into lower case. Here, we will create a custom predictors class wich inherits the TransformerMixin class. This class overrides the transform, fit and get_params methods. We’ll also create a clean_text() function that removes spaces and converts text into lowercase."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6kGV1Hi-oHSX"
      },
      "source": [
        "# Custom Transformer for cleaning the text data\n",
        "class predictors(TransformerMixin):\n",
        "    def transform(self, X, **transform_params):\n",
        "        return [clean_text(text) for text in X]\n",
        "    def fit(self, X, y, **fit_params):\n",
        "        return self\n",
        "    def get_params(self, deep=True):\n",
        "        return {}\n",
        "\n",
        "# Basic function to clean the text \n",
        "def clean_text(text):     \n",
        "    return text.strip().lower()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8DqTLx0Hn1p6"
      },
      "source": [
        "When we classify text, we end up with text snippets matched with their respective labels. But we can’t simply use text strings in our machine learning model; we need a way to convert our text into something that can be represented numerically. So we need a way to represent our text numerically. \n",
        "\n",
        "BoW converts text into the matrix of occurrence of words within a given document. It focuses on whether given words occurred or not in the document, and it generates a matrix that we might see referred to as a BoW matrix or a document term matrix.\n",
        "\n",
        "We can generate a BoW matrix for our text data by using scikit-learn‘s CountVectorizer. In the code below, we’re telling CountVectorizer to use the custom spacy_tokenizer function we built as its tokenizer, and defining the ngram range we want.\n",
        "\n",
        "N-grams are combinations of adjacent words in a given text, where n is the number of words that incuded in the tokens.\n",
        "\n",
        "TF-IDF (Term Frequency-Inverse Document Frequency) - it’s a way of representing how important a particular term is in the context of a given document, based on how many times the term appears and how many other documents that same term appears in. The higher the TF-IDF, the more important that term is to that document.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pUOsvM3XoKxa"
      },
      "source": [
        "vectorizer = CountVectorizer(stop_words = None,tokenizer = tokenizer, ngram_range=(1,1)) \n",
        "tfvectorizer = TfidfVectorizer(tokenizer = tokenizer)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V784nnVKoOwp"
      },
      "source": [
        "X = revs['reviews']\n",
        "y = revs['sentiment']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=77)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "35VyMm6iqRXe"
      },
      "source": [
        "We’ll create a pipeline with three components: a cleaner, a vectorizer, and a classifier. The cleaner uses our predictors class object to clean and preprocess the text. The vectorizer uses countvector objects to create the bag of words matrix for our text. The classifier is an object that performs the logistic regression to classify the sentiments."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4ISk_PFHoddE",
        "outputId": "0aa680c2-b6de-4004-ad0f-9ebc43ede6d7"
      },
      "source": [
        "classifier = LogisticRegression()\n",
        "LRmodel = Pipeline([(\"cleaner\", predictors()),\n",
        "                 ('vectorizer', vectorizer),\n",
        "                 ('classifier', classifier)])\n",
        "\n",
        "# Train the Model\n",
        "LRmodel.fit(X_train,y_train)   \n",
        "LRpred = LRmodel.predict(X_test)\n",
        "print(f'Confusion Matrix:\\n{confusion_matrix(y_test,LRpred)}')\n",
        "print(f'\\nClassification Report:\\n{classification_report(y_test,LRpred)}')\n",
        "print(f'Accuracy: {accuracy_score(y_test,LRpred)*100}%')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confusion Matrix:\n",
            "[[51127  9948]\n",
            " [ 9849 51750]]\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.84      0.84     61075\n",
            "           1       0.84      0.84      0.84     61599\n",
            "\n",
            "    accuracy                           0.84    122674\n",
            "   macro avg       0.84      0.84      0.84    122674\n",
            "weighted avg       0.84      0.84      0.84    122674\n",
            "\n",
            "Accuracy: 83.86210606974583%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zEvE5GV5ria4"
      },
      "source": [
        "[[TN, FP],\n",
        "\n",
        " [FN, TP]]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "loYz6ZSNrY9v",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "18cf7467-cb09-4f08-9e65-3dcc1ccc4656"
      },
      "source": [
        "DTclassifier = DecisionTreeClassifier()\n",
        "DTmodel = Pipeline([(\"cleaner\", predictors()),\n",
        "                 ('vectorizer', vectorizer),\n",
        "                 ('classifier', DTclassifier)])\n",
        "\n",
        "# Train the Model\n",
        "DTmodel.fit(X_train,y_train)   \n",
        "DTpred = DTmodel.predict(X_test)\n",
        "print(f'Confusion Matrix:\\n{confusion_matrix(y_test,DTpred)}')\n",
        "print(f'\\nClassification Report:\\n{classification_report(y_test,DTpred)}')\n",
        "print(f'Accuracy: {accuracy_score(y_test,DTpred)*100}%')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confusion Matrix:\n",
            "[[44843 16232]\n",
            " [16708 44891]]\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.73      0.73      0.73     61075\n",
            "           1       0.73      0.73      0.73     61599\n",
            "\n",
            "    accuracy                           0.73    122674\n",
            "   macro avg       0.73      0.73      0.73    122674\n",
            "weighted avg       0.73      0.73      0.73    122674\n",
            "\n",
            "Accuracy: 73.1483443924548%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WNKX-HK0tNMS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "10c79d28-5183-4a10-b2fe-dc6ac632fb06"
      },
      "source": [
        "SVCclassifier = LinearSVC()\n",
        "SVCmodel = Pipeline([(\"cleaner\", predictors()),\n",
        "                 ('vectorizer', vectorizer),\n",
        "                 ('classifier', SVCclassifier)])\n",
        "\n",
        "# Train the Model\n",
        "SVCmodel.fit(X_train,y_train)   \n",
        "SVCpred = SVCmodel.predict(X_test)\n",
        "print(f'Confusion Matrix:\\n{confusion_matrix(y_test,SVCpred)}')\n",
        "print(f'\\nClassification Report:\\n{classification_report(y_test,SVCpred)}')\n",
        "print(f'Accuracy: {accuracy_score(y_test,SVCpred)*100}%')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confusion Matrix:\n",
            "[[50049 11026]\n",
            " [11294 50305]]\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.82      0.82      0.82     61075\n",
            "           1       0.82      0.82      0.82     61599\n",
            "\n",
            "    accuracy                           0.82    122674\n",
            "   macro avg       0.82      0.82      0.82    122674\n",
            "weighted avg       0.82      0.82      0.82    122674\n",
            "\n",
            "Accuracy: 81.80543554461418%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IY_wYyNPZ5Tt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c85ecacb-33c1-46cf-e88e-a9517194ea91"
      },
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "RFclassifier = RandomForestClassifier(n_estimators = 10)\n",
        "RFmodel = Pipeline([(\"cleaner\", predictors()),\n",
        "                 ('vectorizer', vectorizer),\n",
        "                 ('classifier', RFclassifier)])\n",
        "\n",
        "# Train the Model\n",
        "RFmodel.fit(X_train,y_train)   \n",
        "RFpred = RFmodel.predict(X_test)\n",
        "print(f'Confusion Matrix:\\n{confusion_matrix(y_test,RFpred)}')\n",
        "print(f'\\nClassification Report:\\n{classification_report(y_test,RFpred)}')\n",
        "print(f'Accuracy: {accuracy_score(y_test,RFpred)*100}%')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confusion Matrix:\n",
            "[[51454  9621]\n",
            " [18512 43087]]\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.74      0.84      0.79     61075\n",
            "           1       0.82      0.70      0.75     61599\n",
            "\n",
            "    accuracy                           0.77    122674\n",
            "   macro avg       0.78      0.77      0.77    122674\n",
            "weighted avg       0.78      0.77      0.77    122674\n",
            "\n",
            "Accuracy: 77.06686013336159%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KPqlOeqUqNmW"
      },
      "source": [
        "**Observations :**\n",
        "\n",
        "We can see that since we handled the imbalance in our dataset by undersampling, the precision, recall, f1-score for both classes are almost close in all our models."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1PEJIflmo6Cc"
      },
      "source": [
        "# Conclusions\n",
        "We consider **accuracy** as our evaluation metrics because we wish to see the general performance of the models. And we can confidently use accuracy score because we have dealt with the imbalance in the dataset.\n",
        "\n",
        "We can see that the accuracy of **Logistic Regression** is considerably higher than the other models. So we choose logistic regression as our final model to make predictions. \n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yDixWXhCoGDn"
      },
      "source": [
        "y_pred_final = LRmodel.predict(X)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LXu6hmlEosVt"
      },
      "source": [
        "revs['sentiment'] = y_pred_final"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gtapHKkZ1JYv",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "64fb8522-ebb1-4862-90ad-ea5e3eaf980c"
      },
      "source": [
        "revs.sample(5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>reviewerID</th>\n",
              "      <th>asin</th>\n",
              "      <th>reviews</th>\n",
              "      <th>rating</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>271106</th>\n",
              "      <td>A35VNGMUH59VCH</td>\n",
              "      <td>B00G6Q0K66</td>\n",
              "      <td>very informative book  full of good tips and h...</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2775</th>\n",
              "      <td>A2PHUP1WN3IZPC</td>\n",
              "      <td>B0033UV8HI</td>\n",
              "      <td>i hate to give a book a low rating based on te...</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44395</th>\n",
              "      <td>AE41TLMIZPAE7</td>\n",
              "      <td>B007TKNCSG</td>\n",
              "      <td>what can i say about this short story that wil...</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>185661</th>\n",
              "      <td>A2OJOUTOC3LNZK</td>\n",
              "      <td>B00685NFI0</td>\n",
              "      <td>i had to give this books   thumbs up and if i ...</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>136920</th>\n",
              "      <td>A2K73LH7X2PFR1</td>\n",
              "      <td>B00I2T7BW6</td>\n",
              "      <td>first off  let me say i ve read the dressage c...</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "            reviewerID        asin  ... rating  sentiment\n",
              "271106  A35VNGMUH59VCH  B00G6Q0K66  ...      5          1\n",
              "2775    A2PHUP1WN3IZPC  B0033UV8HI  ...      2          0\n",
              "44395    AE41TLMIZPAE7  B007TKNCSG  ...      3          0\n",
              "185661  A2OJOUTOC3LNZK  B00685NFI0  ...      5          1\n",
              "136920  A2K73LH7X2PFR1  B00I2T7BW6  ...      3          1\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6oAkMnc7pBUe"
      },
      "source": [
        "revs.to_csv('/content/drive/MyDrive/Machine Learning/revs_final.csv', index = False)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}